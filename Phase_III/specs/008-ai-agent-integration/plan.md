# Implementation Plan: AI Agent Integration

**Branch**: `008-ai-agent-integration` | **Date**: 2026-02-09 | **Spec**: [spec.md](./spec.md)
**Input**: Feature specification from `/specs/008-ai-agent-integration/spec.md`

## Summary

Integrate OpenAI Agents SDK with the existing MCP task management tools to enable natural language task management through conversational interactions. The agent will interpret user intent from natural language messages, call the appropriate MCP tools, and provide friendly confirmations. All conversation state will be persisted to PostgreSQL, maintaining stateless backend architecture.

**Key Approach**: Connect OpenAI Agents SDK to the existing stateless MCP server (5 tools already implemented: add_task, list_tasks, complete_task, update_task, delete_task) to enable conversational task management.

## Technical Context

**Language/Version**: Python 3.13+
**Primary Dependencies**: OpenAI Agents SDK, MCP SDK (already installed), FastAPI, SQLModel, httpx
**LLM Provider**: OpenRouter (OpenAI-compatible API) - **No OpenAI API key required**
**LLM Access**: Via OpenRouter API using chat completions model (configured with custom base_url)
**Storage**: PostgreSQL (Neon) via existing Conversation and Message models
**Testing**: pytest with OpenAI Agents SDK test utilities
**Target Platform**: Linux server (FastAPI backend)
**Project Type**: Backend API integration
**Performance Goals**: <2s response time for agent operations, support 100 concurrent conversations
**Constraints**: Stateless backend (no in-memory state), all operations through MCP tools (no direct DB access from agent), conversation context reconstructed from database, OpenRouter API integration instead of direct OpenAI
**Scale/Scope**: Single agent handling 5 MCP tools, multi-turn conversations up to 10+ messages with context

## Constitution Check

*GATE: Must pass before Phase 0 research. Re-check after Phase 1 design.*

### Phase III Principles Assessment

✅ **VII. Agent-First Architecture**: This feature implements the conversational interface using OpenAI Agents SDK as required

✅ **VIII. MCP Tool-Based System Design**: Agent will interact with existing MCP tools only (add_task, list_tasks, complete_task, update_task, delete_task)

✅ **IX. Stateless Backend Principle**: Agent will not maintain in-memory state; conversation history will be reconstructed from Conversation and Message database models on each request

✅ **X. ChatKit-Driven Conversational Interface**: Out of scope for this feature (frontend implementation separate)

✅ **XI. Natural Language Task Management**: Core requirement - agent interprets natural language and maps to MCP tool calls

✅ **XII. Spec-Driven AI Development**: Following `/sp.specify` → `/sp.plan` → `/sp.tasks` → `/sp.implement` workflow

✅ **XIII. Tool Observability and Transparency**: Will log all tool invocations to database for debugging and audit

### Cross-Phase Principles Assessment

✅ **I. Multi-Tier Isolation**: Agent code will reside in `/backend/src/agent/` directory

✅ **II. Persistence First**: All conversation state stored in PostgreSQL; no in-memory storage

✅ **III. Secure by Design**: Agent will receive user_id from JWT and propagate to all MCP tool calls for user-scoped operations

✅ **IV. Zero Manual Coding**: All code generated by Claude Code following Spec-Driven Development

✅ **V. Test-First Discipline**: Will implement tests for agent tool selection and parameter extraction before agent logic

✅ **VI. API Contract Enforcement**: Agent communicates with backend via MCP tools; will add new REST API endpoint for agent invocation

## Project Structure

### Documentation (this feature)

```text
specs/008-ai-agent-integration/
├── plan.md              # This file
├── research.md          # Phase 0 output: OpenAI Agents SDK integration patterns
├── data-model.md        # Phase 1 output: No new models (uses existing Conversation/Message)
├── quickstart.md        # Phase 1 output: Developer guide for agent setup and testing
├── contracts/           # Phase 1 output: Agent API endpoint contract
│   └── agent-api.yaml   # POST /api/v1/agent/chat endpoint specification
└── tasks.md             # Phase 2 output (created by /sp.tasks command)
```

### Source Code (backend)

```text
backend/
├── src/
│   ├── agent/                          # NEW: OpenAI Agents SDK integration
│   │   ├── __init__.py
│   │   ├── config.py                   # Agent configuration (model, instructions)
│   │   ├── agent.py                    # Agent initialization and runner
│   │   ├── tools.py                    # MCP tool adapter for OpenAI Agents SDK
│   │   └── context.py                  # Conversation history loader
│   │
│   ├── api/v1/
│   │   ├── agent.py                    # NEW: POST /api/v1/agent/chat endpoint
│   │   └── router.py                   # UPDATE: Register agent endpoint
│   │
│   ├── models/                         # EXISTING: No changes needed
│   │   ├── conversation.py             # Already implemented
│   │   └── message.py                  # Already implemented
│   │
│   ├── mcp/                            # EXISTING: No changes needed
│   │   ├── server.py                   # Already implemented (5 tools)
│   │   ├── tools/                      # Already implemented
│   │   └── schemas/                    # Already implemented
│   │
│   └── services/
│       ├── conversation_service.py     # NEW: Conversation CRUD operations
│       └── message_service.py          # NEW: Message persistence
│
└── tests/
    ├── agent/                          # NEW: Agent tests
    │   ├── test_agent.py               # Agent tool selection and parameter extraction
    │   ├── test_tools.py               # MCP tool adapter tests
    │   └── test_context.py             # Conversation history reconstruction tests
    │
    └── api/v1/
        └── test_agent_api.py           # NEW: Agent endpoint integration tests
```

**Structure Decision**: Backend-only implementation following existing FastAPI + SQLModel architecture. Agent code in new `/src/agent/` directory alongside existing `/src/mcp/` MCP server. Agent integrates with existing MCP tools via MCP client connection. No frontend changes in this feature (ChatKit integration is separate).

## Complexity Tracking

> **Fill ONLY if Constitution Check has violations that must be justified**

No constitution violations. All principles satisfied.

## Phase 0: Research & Technical Decisions

### Research Tasks

1. **OpenAI Agents SDK MCP Integration Pattern**
   - **Question**: How does OpenAI Agents SDK connect to external MCP servers?
   - **Research**: Review OpenAI Agents SDK documentation for MCP client integration
   - **Decision**: Determine if using MCP client within agent or wrapping MCP tools as agent-native tools
   - **Output**: Integration pattern and code examples

2. **Conversation History Management**
   - **Question**: How to efficiently reconstruct conversation context from database for each request?
   - **Research**: Optimal message window size, pagination strategy, performance considerations
   - **Decision**: Load last N messages vs. time-windowed vs. token-budget-based
   - **Output**: Context loading strategy with rationale

3. **Agent System Prompt Design**
   - **Question**: What instructions enable accurate natural language → tool selection mapping?
   - **Research**: Best practices for prompt engineering with OpenAI Agents SDK
   - **Decision**: System prompt structure, tool descriptions, error handling instructions
   - **Output**: Initial system prompt template

4. **MCP Tool Error Handling**
   - **Question**: How should agent handle MCP tool failures or invalid responses?
   - **Research**: OpenAI Agents SDK error handling patterns, retry logic, user-facing error messages
   - **Decision**: Error propagation strategy, user-friendly message templates
   - **Output**: Error handling architecture

5. **Agent Response Streaming**
   - **Question**: Should agent responses be streamed to frontend or sent as complete messages?
   - **Research**: OpenAI Agents SDK streaming capabilities, FastAPI SSE support
   - **Decision**: Immediate vs. streaming response delivery
   - **Output**: Response delivery architecture (for future ChatKit integration)

### Expected Outcomes

All research findings will be documented in `research.md` with:
- **Decision**: Clear choice made
- **Rationale**: Why this choice over alternatives
- **Alternatives Considered**: What other options were evaluated
- **Implementation Notes**: Key technical details for tasks

## Phase 1: Design & Contracts

### Design Artifacts

#### 1. Data Model (`data-model.md`)

**No new database models required**. Uses existing models:

- **Conversation** (already implemented in `src/models/conversation.py`)
  - Fields: id, user_id, created_at, updated_at
  - Relationship: One-to-many with Message

- **Message** (already implemented in `src/models/message.py`)
  - Fields: id, conversation_id, user_id, role, content, created_at
  - Relationship: Many-to-one with Conversation

**Rationale**: Conversation and Message models already provide required structure for storing chat history. Agent reads/writes messages through these models without needing new tables.

**Document will include**:
- Entity relationship diagram showing Conversation → Messages
- Field validation rules (message content max length, role enum)
- Query patterns for efficient conversation history retrieval
- Index strategy for user_id and conversation_id lookups

#### 2. API Contracts (`contracts/agent-api.yaml`)

**New Endpoint**: POST /api/v1/agent/chat

**Request Schema**:
```yaml
AgentChatRequest:
  type: object
  required:
    - conversation_id
    - message
  properties:
    conversation_id:
      type: integer
      description: Existing conversation ID (0 to create new conversation)
    message:
      type: string
      maxLength: 2000
      description: User message in natural language
```

**Response Schema**:
```yaml
AgentChatResponse:
  type: object
  properties:
    conversation_id:
      type: integer
      description: Conversation ID (new or existing)
    user_message_id:
      type: integer
      description: Stored user message ID
    agent_message_id:
      type: integer
      description: Stored agent response message ID
    agent_response:
      type: string
      description: Agent's natural language response
    tool_calls:
      type: array
      items:
        $ref: '#/components/schemas/ToolCall'
      description: Optional array of tool invocations for debugging

ToolCall:
  type: object
  properties:
    tool_name:
      type: string
      enum: [add_task, list_tasks, complete_task, update_task, delete_task]
    arguments:
      type: object
      description: Tool input parameters
    result:
      type: object
      description: Tool output
```

**Error Responses**:
- 400: Invalid request (malformed message, missing required fields)
- 401: Unauthorized (missing or invalid JWT)
- 403: Forbidden (conversation_id belongs to different user)
- 404: Conversation not found
- 500: Internal server error (MCP tool failure, agent error)

**Document will include**:
- Complete OpenAPI 3.0 specification
- Example requests and responses for each tool operation
- Error response formats with user-friendly messages
- Authentication requirements (Better Auth JWT in Authorization header)

#### 3. Developer Quickstart (`quickstart.md`)

**Contents**:
1. **Setup Instructions**
   - Install OpenAI Agents SDK via uv
   - Configure OPENROUTER_API_KEY in .env (not OPENAI_API_KEY)
   - Configure OpenRouter base URL (https://openrouter.ai/api/v1)
   - Run database migrations (already complete for Conversation/Message)
   - Start MCP server (existing process)
   - Start FastAPI backend

2. **Testing Agent Locally**
   - curl examples for POST /api/v1/agent/chat
   - Example conversations demonstrating each tool
   - Debugging tool invocations via optional tool_calls response field

3. **Configuration Options**
   - Agent model selection via OpenRouter (e.g., openai/gpt-4o, anthropic/claude-3-5-sonnet)
   - OpenRouter base URL configuration
   - System prompt customization
   - MCP server connection settings
   - Conversation history window size

4. **Troubleshooting**
   - Common errors and solutions
   - MCP server connection issues
   - Agent not selecting correct tools
   - Database query performance optimization

### Agent Context Update

After Phase 1 design completion, run:
```bash
.specify/scripts/bash/update-agent-context.sh claude
```

This will update `.claude/context.md` with:
- OpenAI Agents SDK integration patterns
- MCP tool adapter architecture
- Conversation history loading strategy
- Agent system prompt template
- New API endpoint routes

## Phase 2: Implementation Steps (High-Level)

*Note: Detailed tasks will be generated by `/sp.tasks` command*

### Step 1: Agent Foundation
- Install OpenAI Agents SDK dependency
- Create agent configuration module
- Define system prompt for task management
- Initialize agent with MCP tool connections

### Step 2: MCP Tool Integration
- Create MCP client adapter for OpenAI Agents SDK
- Connect to existing MCP server (5 tools)
- Test tool invocation from agent
- Validate tool parameter extraction

### Step 3: Conversation Context Management
- Implement conversation service (CRUD operations)
- Implement message service (persistence)
- Create conversation history loader
- Optimize database queries for history retrieval

### Step 4: Agent API Endpoint
- Create POST /api/v1/agent/chat endpoint
- Integrate JWT authentication
- Implement request validation
- Connect agent runner with conversation persistence

### Step 5: Error Handling
- Implement MCP tool error handling
- Create user-friendly error messages
- Add logging for debugging
- Handle edge cases (timeouts, invalid inputs)

### Step 6: Testing
- Write agent tool selection tests
- Write parameter extraction tests
- Write conversation flow integration tests
- Write API endpoint tests
- Test with representative user messages

### Step 7: Documentation
- Update backend README with agent setup
- Document agent configuration options
- Add example conversations
- Document debugging procedures

## Non-Functional Requirements

### Performance
- Agent response time: <2 seconds for simple operations (<3 tool calls)
- Conversation history loading: <200ms for last 20 messages
- Concurrent conversation support: 100+ simultaneous agent requests
- Database connection pooling configured for agent traffic

### Security
- All MCP tool calls include user_id from JWT for authorization
- Agent cannot access tasks belonging to other users
- Conversation access validated (conversation.user_id == JWT.user_id)
- Rate limiting on agent endpoint to prevent abuse

### Reliability
- Graceful handling of MCP server unavailability
- Retry logic for transient MCP tool failures
- Agent errors do not crash FastAPI server
- All errors logged with sufficient context for debugging

### Observability
- Log all agent requests with conversation_id and user_id
- Log all MCP tool invocations with parameters and results
- Track agent response latency
- Monitor tool selection accuracy (manual review initially)

## Dependencies

### Existing Infrastructure
- ✅ PostgreSQL database with Conversation and Message tables
- ✅ MCP server with 5 task management tools
- ✅ FastAPI backend with JWT authentication
- ✅ Better Auth integration for user authentication

### New Dependencies
- OpenAI Agents SDK (Python package)
- MCP Python SDK (already installed)
- httpx (for MCP server communication, may already be installed)

### External Services
- OpenRouter API (for LLM calls via Agents SDK - OpenAI-compatible endpoint)
- Neon PostgreSQL (existing)

## Risk Assessment

### High Risk
- **Agent not selecting correct tools**: Mitigate with comprehensive system prompt engineering and testing
- **MCP tool parameter extraction errors**: Mitigate with clear tool descriptions and validation in tests

### Medium Risk
- **Performance degradation with long conversations**: Mitigate with conversation history window limit
- **OpenRouter API rate limits or costs**: Mitigate with request caching and usage monitoring
- **OpenRouter API compatibility**: Mitigate by testing OpenAI Agents SDK with OpenRouter base_url configuration

### Low Risk
- **MCP server availability**: Existing infrastructure, minimal risk
- **Database performance**: Existing models with proper indexes

## Success Metrics

- ✅ Agent successfully calls all 5 MCP tools based on natural language input
- ✅ 95%+ accuracy for tool selection on clear user requests
- ✅ <2 second average response time for single-tool operations
- ✅ All conversation history persisted and retrievable after server restart
- ✅ Zero cross-user data leakage (enforced by tests)
- ✅ Agent provides friendly, conversational responses (not robotic)
- ✅ Error messages are actionable and user-friendly

## Next Steps

1. **Run `/sp.tasks`** to generate detailed implementation tasks from this plan
2. **Execute Phase 0 research** to resolve all technical decisions
3. **Generate Phase 1 design artifacts** (research.md, data-model.md, contracts/, quickstart.md)
4. **Begin implementation** following dependency-ordered tasks

---

**Plan Status**: ✅ Ready for task generation
**Prerequisites Met**: Conversation/Message models implemented, MCP server operational, JWT auth configured
**Estimated Complexity**: Medium (agent integration with existing tools, no new data models)
