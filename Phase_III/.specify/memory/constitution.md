<!--
  SYNC IMPACT REPORT
  ==================
  Version change: 2.0.0 → 2.1.0 (MINOR - Added project structure and deliverables requirements)

  Modified principles:
    - I. Multi-Tier Isolation → Updated to reflect /frontend, /backend (includes agent code), /specs structure

  Added sections:
    - Project Structure & Deliverables (Phase III)

  Removed sections: None

  Templates requiring updates:
    - ✅ plan-template.md (supports repository structure documentation)
    - ✅ spec-template.md (supports deliverables documentation)
    - ✅ tasks-template.md (supports directory structure awareness)

  Follow-up TODOs: None
-->

# Full-Stack Todo Evolution Constitution

**Project Phases**:
- **Phase I**: In-memory Python CLI (complete)
- **Phase II**: Full-stack web app with Next.js + FastAPI + PostgreSQL (complete)
- **Phase III**: AI-powered conversational chatbot with OpenAI Agents SDK + MCP tools (active)

---

## Core Principles (Phases I–III)

### I. Multi-Tier Isolation

All code MUST reside strictly within designated directories:
- **Frontend code**: `/frontend/` (Next.js UI with ChatKit interface)
- **Backend code**: `/backend/` (FastAPI REST API + OpenAI Agents SDK + MCP tools) *(Phase III)*
- **Specification files**: `/specs/` (Agent and MCP tool specifications) *(Phase III)*

**Rationale**: Clear separation enables independent deployment, testing, and scaling of each architectural tier. Frontend handles presentation and chat UI; backend handles business logic, data persistence, and conversational AI orchestration. Specifications live separately for documentation and discoverability. This isolation prevents cross-contamination and maintains clean boundaries.

**Enforcement**:
- Code reviews MUST reject any code outside designated directories
- Build pipelines MUST only process files within the isolation boundary
- Shared types or contracts MUST be duplicated or published as packages, never imported across tiers directly
- Communication between frontend and backend MUST occur only via documented protocols (REST API, MCP tools)

### II. Persistence First

All data MUST be persisted to Neon PostgreSQL using SQLModel as the ORM layer. In-memory storage is prohibited for production data.

**Phase III Extension**: All conversation state (messages, agent runs, tool invocations) MUST be stored in the database. The backend MUST remain stateless—no in-memory session or conversation context. Each request MUST be independently reproducible from database state.

**Rationale**: Durable persistence enables conversation history, multi-device access, audit trails, and system resilience. Stateless backend design ensures horizontal scalability and simplifies deployment.

**Requirements**:
- Every entity (including messages, conversations, agent runs, tool calls) MUST have a corresponding SQLModel class
- Database migrations MUST be managed via Alembic
- Connection pooling MUST be configured for production workloads
- All queries MUST use parameterized statements (SQLModel handles this by default)
- Conversation state MUST be stored in normalized tables with proper foreign keys and indexes
- Agent context MUST be reconstructed from database on each request

### III. Secure by Design

Every API request MUST be validated via Better Auth JWT tokens. No unauthenticated endpoints are permitted except health checks and public metadata.

**Phase III Extension**: All MCP tool invocations MUST include user context derived from JWT tokens. Agent tools MUST enforce user-scoped authorization for all task operations (create, read, update, delete). Cross-user data access MUST be blocked at the database query level.

**Rationale**: Security is not an afterthought. Authentication and authorization MUST be baked into the architecture from day one to prevent data leakage and unauthorized access. Agents operate on behalf of users and MUST respect user isolation boundaries.

**Requirements**:
- JWT verification MUST use shared secret between Next.js and FastAPI
- Tokens MUST include user identity claims for authorization decisions
- Token expiry MUST be enforced; refresh token flow MUST be implemented
- All endpoints MUST declare their authentication requirements explicitly
- Failed authentication MUST return 401; failed authorization MUST return 403
- Agent tools MUST propagate user_id from JWT to backend for all operations
- Database queries MUST filter by user_id to enforce data isolation

### IV. Zero Manual Coding

All code within project directories MUST be generated by Claude Code. Manual edits are prohibited.

**Phase III Extension**: Agent system prompts, MCP tool definitions, and ChatKit configurations are considered code artifacts and MUST be generated by Claude Code following the Spec → Plan → Tasks → Implement workflow.

**Rationale**: This project demonstrates AI-assisted development workflow. Maintaining this constraint ensures reproducibility, traceability, and validates the AI coding assistant's capabilities across all phases including agent and tool development.

**Enforcement**:
- Every code change MUST be traceable to a Claude Code session via PHR
- Manual hotfixes are prohibited; issues MUST be resolved through new Claude Code prompts
- Code reviews MUST verify AI-generation provenance
- Prompt engineering and tool schema definitions fall under this principle

### V. Test-First Discipline

Tests SHOULD be written before implementation when explicitly requested. Red-Green-Refactor cycle is the preferred development pattern.

**Phase III Extension**: Agent behavior tests SHOULD verify tool selection, parameter extraction, conversation flow, and natural language understanding before implementing agent logic.

**Rationale**: Test-first development catches design issues early and ensures every feature has verification coverage from inception. For AI systems, tests codify expected behavior and catch regressions in prompt engineering and tool selection logic.

**Guidelines**:
- Contract tests for API endpoints SHOULD be defined before implementation
- Integration tests SHOULD cover critical user journeys (including conversational flows)
- Unit tests SHOULD cover business logic in isolation
- Agent tests SHOULD verify correct tool selection for representative user inputs
- Agent tests SHOULD validate parameter extraction from natural language
- Test files MUST reside in appropriate `tests/` directories per tier

### VI. API Contract Enforcement

Frontend and backend MUST communicate exclusively via REST API with JSON payloads. Agent and backend MUST communicate via MCP tools. All contracts MUST be documented and versioned.

**Phase III Extension**: All task operations MUST be exposed as MCP tools using the Official MCP SDK. Tool definitions serve as the contract between agent and backend. Tool schemas MUST match backend API contracts exactly.

**Rationale**: Explicit contracts enable independent development of each tier, facilitate testing, and provide clear documentation for all consumers. MCP provides a standard, discoverable interface for agent tools. Frontend can use REST API directly or via agent; both paths must honor the same contracts.

**Requirements**:
- All REST endpoints MUST follow REST conventions (proper HTTP methods, status codes)
- Request/response schemas MUST be documented (OpenAPI/Swagger auto-generation via FastAPI)
- Breaking changes MUST increment API version
- Error responses MUST follow a consistent structure
- MCP tool definitions MUST declare parameters, types, and descriptions
- Tool responses MUST match documented schemas
- Tools MUST invoke backend REST endpoints (not bypass them)

---

## Phase III Principles: AI-Powered Chatbot

### VII. Agent-First Architecture

The conversational interface is the PRIMARY user interaction model for task management in Phase III. All user task operations MUST be handled through an AI agent built with the OpenAI Agents SDK.

**Rationale**: Modern AI agents provide natural language understanding, context management, and intelligent tool orchestration. Agent-first design enables users to manage tasks through conversation rather than clicking through UI forms, lowering the barrier to entry and improving accessibility.

**Requirements**:
- The agent MUST be built using the OpenAI Agents SDK
- The agent MUST handle multi-turn conversations with context preservation
- The agent MUST provide helpful, friendly responses for all user inputs
- The agent MUST handle ambiguous requests and ask clarifying questions when needed
- The agent MUST confirm destructive operations before executing
- The frontend MUST render agent responses in a conversational chat interface
- The REST API MUST remain available for direct programmatic access (not deprecated)

### VIII. MCP Tool-Based System Design

All task operations (create, read, update, delete, list) MUST be exposed as stateless MCP tools using the Official MCP SDK. The agent MUST interact with the application exclusively through these tools.

**Rationale**: MCP (Model Context Protocol) provides a standard, discoverable, and type-safe interface for agent tools. Tools encapsulate backend logic, enforce contracts, and provide clear boundaries for what the agent can do. Stateless tools simplify testing, debugging, and horizontal scaling.

**Requirements**:
- Every backend task operation MUST have a corresponding MCP tool definition
- Tools MUST be implemented using the Official MCP SDK
- Tools MUST be stateless—no in-memory state between invocations
- Tools MUST declare their parameters with types, descriptions, and validation rules
- Tools MUST validate inputs and return structured, typed responses
- Tools MUST enforce user-scoped authorization (user_id propagation)
- Tool errors MUST be returned in a format the agent can communicate to users
- Tool definitions MUST be co-located with agent code in `/backend/`
- Tools MUST call backend REST API endpoints (not directly access database)

### IX. Stateless Backend Principle

The backend MUST remain stateless. No in-memory session or conversation state is permitted. All conversation history MUST be stored in the database. Each request MUST be independently reproducible.

**Rationale**: Stateless backends enable horizontal scaling, simplify deployment, avoid session management complexity, and improve fault tolerance. Storing conversation state in the database enables multi-device access, conversation history persistence, audit trails, and disaster recovery.

**Requirements**:
- Backend API MUST NOT maintain in-memory session state
- Backend MUST NOT cache conversation context in-memory
- Every agent message MUST be stored in a `messages` table
- Every agent run MUST be stored in an `agent_runs` table
- Tool invocations MUST be logged to database for traceability and debugging
- Conversation context MUST be reconstructed from database on each request
- Database schema MUST support efficient queries for recent conversation history
- Proper indexing MUST be configured (user_id, conversation_id, timestamp)
- Conversation retrieval MUST be optimized (e.g., load last N messages, not entire history)

### X. ChatKit-Driven Conversational Interface

The frontend MUST use OpenAI ChatKit as the primary user interface for task management. All task operations MUST be accessible through natural language via the chat interface.

**Rationale**: ChatKit provides a modern, accessible, and mobile-friendly conversational UI. It handles message rendering, streaming responses, typing indicators, and accessibility features out of the box. Users can manage tasks without learning commands or navigating complex UIs.

**Requirements**:
- Frontend MUST integrate OpenAI ChatKit for the chat interface
- Chat interface MUST support streaming responses from the agent
- Chat interface MUST display typing indicators during agent processing
- Chat interface MUST render tool calls and results transparently when appropriate
- Chat interface MUST support message history scrolling and search
- Chat interface MUST be responsive and mobile-friendly
- Chat interface MUST meet WCAG 2.1 Level AA accessibility standards
- Traditional UI views (task list, dashboard) MAY coexist as secondary interfaces

### XI. Natural Language Task Management

The system MUST interpret user intent from conversational input and map it to the appropriate MCP tools. All task CRUD operations MUST be performable via natural language. All actions MUST return clear, friendly confirmations.

**Rationale**: Natural language interfaces lower the barrier to entry and make task management more accessible to all users. Users can express intent without memorizing commands, clicking through forms, or navigating complex UIs. Friendly confirmations build trust and provide feedback.

**Requirements**:
- Agent MUST support commands like:
  - "add a task to buy milk"
  - "show my tasks"
  - "mark task 3 as done"
  - "delete the grocery task"
  - "what tasks are due today?"
- Agent MUST handle ambiguous or incomplete requests gracefully
- Agent MUST ask clarifying questions when intent is unclear
- Agent MUST confirm destructive operations (delete, bulk updates) before executing
- Agent MUST provide helpful feedback after each operation (e.g., "Task 'Buy milk' has been added")
- Agent MUST extract entities (titles, due dates, priorities) from natural language
- Agent MUST support bulk operations when requested (e.g., "mark all today's tasks as done")
- Agent MUST handle errors gracefully and provide actionable error messages
- Agent responses MUST be conversational, friendly, and concise

### XII. Spec-Driven AI Development

All AI, agent, MCP, and chat features MUST follow the same Spec-Driven Development workflow as traditional features. Prompts and tool definitions are code artifacts requiring the same rigor.

**Rationale**: AI systems are complex software systems that benefit from upfront planning, documented requirements, and testable acceptance criteria. Prompts, tool definitions, and conversation flows require design, review, and iteration just like application code. Ad-hoc prompt engineering leads to inconsistent behavior and regressions.

**Requirements**:
- Agent system prompts MUST be documented in spec artifacts
- Tool definitions MUST be specified in plan artifacts before implementation
- Conversation flows MUST be defined as user stories with acceptance scenarios
- Agent behavior MUST have measurable, testable success criteria
- All AI/agent features MUST follow: `/sp.specify` → `/sp.plan` → `/sp.tasks` → `/sp.implement`
- Prompt engineering iterations MUST be tracked
- Significant prompt/tool decisions MUST be documented in ADRs
- Agent tests MUST verify expected behavior for representative inputs
- Regression tests MUST catch prompt engineering regressions

### XIII. Tool Observability and Transparency

All agent tool calls MUST be logged, traceable, and optionally returned in API responses. Tool execution MUST be debuggable and auditable.

**Rationale**: AI agent behavior can be opaque and difficult to debug. Logging all tool invocations enables debugging, auditing, compliance, and understanding agent behavior. Transparent tool calls help users understand what the agent is doing on their behalf. Observability is essential for production AI systems.

**Requirements**:
- Every tool invocation MUST be logged to database with:
  - Timestamp
  - User ID
  - Agent run ID
  - Tool name
  - Input parameters
  - Output result or error
  - Execution duration
- Tool logs MUST be queryable for debugging and audit purposes
- Tool calls MAY be returned in API responses when requested (e.g., debug mode)
- Frontend MAY display tool calls transparently in the chat UI for power users
- Tool execution errors MUST be logged with stack traces for debugging
- Tool performance metrics (latency, success rate) SHOULD be monitored
- Logs MUST comply with data privacy regulations (no PII in logs unless necessary and protected)

---

## Project Structure & Deliverables

### Repository Structure

The GitHub repository MUST contain the following directory structure:

```
/frontend          # ChatKit-based conversational UI (Next.js + TypeScript)
/backend           # FastAPI + OpenAI Agents SDK + MCP tools (Python)
/specs             # Specification files for agent and MCP tools
/history           # Prompt History Records (PHRs) and Architecture Decision Records (ADRs)
/.specify          # Spec-Driven Development templates and configuration
README.md          # Setup instructions and project overview
```

**Requirements**:
- `/frontend` MUST contain the Next.js application with ChatKit integration
- `/backend` MUST contain:
  - FastAPI application code
  - OpenAI Agents SDK integration
  - MCP tool definitions and implementations
  - SQLModel database models
  - Alembic database migration scripts
  - Test suites (pytest)
- `/specs` MUST contain:
  - Agent system prompt specifications
  - MCP tool schema definitions
  - API contract documentation
- Database migration scripts MUST be organized under `/backend/alembic/versions/`
- README.md MUST include:
  - Project overview and architecture
  - Setup instructions for local development
  - Environment variable configuration guide
  - Database setup and migration instructions
  - Running tests
  - Deployment guidance

### Working Chatbot Deliverables

The Phase III implementation MUST deliver a working chatbot with the following capabilities:

**Core Functionality**:
1. **Natural Language Task Management**:
   - Create, read, update, delete tasks through conversational input
   - Support commands like "add a task to buy milk", "show my tasks", "mark task 3 as done"
   - Extract entities (titles, due dates, priorities) from natural language

2. **Conversation Context Persistence**:
   - Store all conversation history in PostgreSQL database
   - Maintain conversation context across requests (stateless server reconstructs from database)
   - Resume conversations after server restart without data loss
   - Support multi-device access (same conversation accessible from different clients)

3. **Helpful User Experience**:
   - Provide clear, friendly responses with action confirmations
   - Handle ambiguous requests by asking clarifying questions
   - Confirm destructive operations before executing (e.g., "Are you sure you want to delete all tasks?")
   - Display typing indicators during agent processing
   - Stream responses in real-time for better responsiveness

4. **Error Handling**:
   - Handle errors gracefully without exposing internal details to users
   - Provide actionable error messages (e.g., "I couldn't find that task. Would you like to see all your tasks?")
   - Log all errors to database for debugging and monitoring
   - Recover from transient failures automatically when possible

5. **Tool-Based Architecture**:
   - Expose all task operations as MCP tools
   - Log all tool invocations to database for traceability
   - Enforce user-scoped authorization for all operations
   - Support tool execution observability (optionally display tool calls in UI)

**Acceptance Criteria**:
- User can manage their entire task list through natural language conversation
- No data loss occurs on server restart
- All operations are user-scoped (no cross-user data access)
- System handles at least 100 concurrent conversations without performance degradation
- Average response latency under 2 seconds for simple operations
- All errors are logged with sufficient context for debugging

---

## Technology Standards

### Backend Stack (Phase II–III)
- **Language**: Python 3.13+
- **Framework**: FastAPI (latest stable)
- **ORM**: SQLModel
- **Database**: Neon PostgreSQL
- **Auth**: Better Auth JWT (shared secret verification)
- **Migrations**: Alembic

### Frontend Stack (Phase II–III)
- **Framework**: Next.js 16+ (App Router)
- **Chat UI**: OpenAI ChatKit *(Phase III)*
- **Styling**: Tailwind CSS with custom design system
- **Typography**: Poppins font family
- **Language**: TypeScript (strict mode)
- **Auth**: Better Auth client integration
- **UI Components**: shadcn/ui

### Agent Stack (Phase III)
- **Framework**: OpenAI Agents SDK
- **LLM**: OpenAI GPT-4 or compatible model
- **Tool Protocol**: MCP (Model Context Protocol) via Official MCP SDK
- **Language**: Python 3.13+ (preferred) or TypeScript
- **State Management**: Database-backed (PostgreSQL via backend API)
- **Tool Definitions**: MCP schema with type validation

### Communication Protocols
- **Frontend ↔ Backend**: REST API over HTTPS (JSON payloads)
- **Agent ↔ Backend**: MCP tools invoking REST API endpoints
- **Agent ↔ Frontend**: Server-Sent Events (SSE) or WebSocket for streaming responses

### Development Tools
- **Package Management**: uv (backend/agent), pnpm (frontend)
- **Linting**: ruff (Python), ESLint (TypeScript)
- **Formatting**: ruff format (Python), Prettier (TypeScript)
- **Testing**: pytest (backend/agent), Jest/Vitest (frontend)
- **Type Checking**: mypy (Python), tsc (TypeScript)

---

## Development Workflow

### Spec-Driven Development (SDD) Cycle
1. **`/sp.specify`** - Define feature requirements and acceptance criteria
2. **`/sp.plan`** - Create implementation architecture and technical design
3. **`/sp.tasks`** - Generate actionable, dependency-ordered tasks
4. **`/sp.implement`** - Execute tasks with AI assistance
5. **Validate** - Test against spec and iterate

### Phase III Agent Development Flow
1. Define conversational user stories in spec (e.g., "As a user, I want to add a task by saying 'remind me to buy milk'")
2. Design tool contracts in plan (tool names, parameters, backend endpoint mappings, error handling)
3. Generate tasks for:
   - Tool implementation (MCP schema + backend wiring)
   - Agent system prompt configuration
   - ChatKit integration
   - Tests (tool selection, parameter extraction, conversation flow)
4. Implement MCP tools (definitions + backend endpoint invocation)
5. Configure agent system prompt and tool selection logic
6. Integrate ChatKit in frontend with streaming response support
7. Test conversational flows with representative user inputs
8. Iterate on prompts and tools based on test results
9. Document significant decisions in ADRs (tool design, prompt strategies, error handling)

### Version Control
- **Feature branches**: `###-feature-name` format
- **Commits** MUST reference task IDs when applicable
- **PRs** MUST include summary and test plan
- **Agent prompts and tool definitions** in version control treated as code

### Quality Gates
- All tests MUST pass before merge
- Linting MUST pass with zero warnings
- Type checking MUST pass (mypy for Python, tsc for TypeScript)
- Security scans SHOULD be run on PRs
- Agent tests SHOULD verify tool selection for key conversational scenarios
- MCP tool schemas MUST validate successfully

---

## Governance

This constitution supersedes all other development practices for all phases of the Full-Stack Todo Evolution project.

### Amendment Process
1. Propose change via `/sp.constitution` command with rationale
2. Document impact on existing code and templates
3. Update version according to semantic versioning:
   - **MAJOR**: Principle removal, backward-incompatible redefinition, or paradigm shift (e.g., adding agent tier)
   - **MINOR**: New principle or materially expanded guidance
   - **PATCH**: Clarifications, wording, or non-semantic refinements
4. Update dependent templates and documentation
5. Create Sync Impact Report documenting all changes

### Compliance
- All PRs MUST verify compliance with applicable principles
- Violations MUST be documented with justification in Complexity Tracking section of plan.md
- Architectural decisions SHOULD be recorded via ADR when meeting significance criteria
- Agent prompts, tool definitions, and ChatKit configurations fall under same compliance requirements as application code

### Runtime Guidance
- Use `.specify/` templates for all specification artifacts
- Consult this constitution before making architectural decisions
- When in doubt, ask for clarification rather than assume
- Document significant prompt engineering decisions in ADRs
- Test agent behavior thoroughly before deploying to production
- Monitor tool invocation logs for anomalies and errors

### Cross-Phase Principles
These principles apply across ALL phases (I, II, III):
- **Multi-Tier Isolation** (I) - Backend now includes agent code (Agents SDK + MCP) in Phase III
- **Persistence First** (II) - Extended with conversation state in Phase III
- **Secure by Design** (III) - Extended with agent tool authorization in Phase III
- **Zero Manual Coding** (IV) - Extended with AI artifacts in Phase III
- **Test-First Discipline** (V) - Extended with agent tests in Phase III
- **API Contract Enforcement** (VI) - Extended with MCP tools in Phase III

Phase III principles (VII–XIII) are additive and do not override Phase I/II principles.

---

**Version**: 2.1.0 | **Ratified**: 2026-01-22 | **Last Amended**: 2026-02-09
